{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f944ae8d3b4558b2",
   "metadata": {},
   "source": [
    "# PART 2 - NER SERVICE WITH FASTAPI & DOCKER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad5770387007260",
   "metadata": {},
   "source": [
    "For the second part of the project, we are going to create a service that receives NER requests and outputs the extracted entities from within the text sent, with their labels and confidence scores.\n",
    "We will divide this part in two steps:\n",
    "1) Creating an architecture that allows users to send text to an API and receive the extracted entities and their class - we will achieve this using a FastAPI architecture\n",
    "2) Building a Docker container to run this service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358668b31ddbf20",
   "metadata": {},
   "source": [
    "## 1. Fast API Architecture - defining and running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129e4b41875ff6a",
   "metadata": {},
   "source": [
    "We will write a brief script implementing a FastAPI architecture. I am copying the code here below in order to better organize the Jupyter Notebook, but I also have a .py file inside this folder with the same code, in order to call it from the terminal when we'll run the service and the Docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b266bcd03b0c7a1",
   "metadata": {},
   "source": [
    "Defining imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "e8bf7b2798162d5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:52:38.271777Z",
     "start_time": "2024-10-16T06:52:34.611114Z"
    }
   },
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import torch\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "76fe478c85acf6b5",
   "metadata": {},
   "source": [
    "Defining FastAPI code"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:53:23.803043Z",
     "start_time": "2024-10-16T06:53:23.082977Z"
    }
   },
   "source": [
    "# Input model\n",
    "class TextRequest(BaseModel):\n",
    "    text: str\n",
    "\n",
    "\n",
    "# Initializing\n",
    "app = FastAPI()\n",
    "\n",
    "# Loading the pre-trained model and tokenizer from Hugging Face\n",
    "MODEL_NAME = \"CyberPeace-Institute/SecureBERT-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1  # -1 == CPU\n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"first\", device=device)\n",
    "\n",
    "\n",
    "@app.post(\"/ner\")\n",
    "async def extract_entities(text_request: TextRequest):\n",
    "    \"\"\"Extract named entities from text.\"\"\"\n",
    "    \n",
    "    text = text_request.text\n",
    "    if not text:\n",
    "        raise HTTPException(status_code=400, detail=\"Text must be provided.\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        entities = ner_pipeline(text)\n",
    "\n",
    "        # Converting numpy types to native types - for JSON\n",
    "        for entity in entities:\n",
    "            if isinstance(entity.get('score'), np.float32):\n",
    "                entity['score'] = float(entity['score'])\n",
    "\n",
    "        return {\"entities\": entities}\n",
    "\n",
    "    except Exception as e:\n",
    "        # Error handling\n",
    "        print(f\"Error during NER processing: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=\"Internal Server Error during NER processing.\")\n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "4565934d8a940107",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83e200a6fef9bce9",
   "metadata": {},
   "source": [
    "After defining the FastAPI architecture, we're going to run it with a terminal command.\n",
    "\n",
    "Note: we will use the prefix ! to run shell commands in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bd374ae587cc4ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T09:37:51.091106Z",
     "start_time": "2024-10-15T09:37:20.696886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m:     Started server process [\u001B[36m52309\u001B[0m]\r\n",
      "\u001B[32mINFO\u001B[0m:     Waiting for application startup.\r\n",
      "\u001B[32mINFO\u001B[0m:     Application startup complete.\r\n",
      "\u001B[32mINFO\u001B[0m:     Uvicorn running on \u001B[1mhttp://localhost:8000\u001B[0m (Press CTRL+C to quit)\r\n",
      "^C\r\n",
      "\u001B[32mINFO\u001B[0m:     Shutting down\r\n",
      "\u001B[32mINFO\u001B[0m:     Waiting for application shutdown.\r\n",
      "\u001B[32mINFO\u001B[0m:     Application shutdown complete.\r\n",
      "\u001B[32mINFO\u001B[0m:     Finished server process [\u001B[36m52309\u001B[0m]\r\n"
     ]
    }
   ],
   "source": [
    "!uvicorn ner_service_fastapi:app --host localhost --port 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c309d961dbef60e3",
   "metadata": {},
   "source": [
    "The FastAPI service is up and running!\n",
    "\n",
    "We can, for example, go to the docs URL to see that the service is up:\n",
    "http://localhost:8000/docs\n",
    "\n",
    "We will want to stop this cell from running before the next step, as we'll want to run some more shell commands and we don't want it to block them "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a7448b629a5e9",
   "metadata": {},
   "source": [
    "## 2. Docker Container - defining a Dockerfile, building and running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06bbc07a41f702",
   "metadata": {},
   "source": [
    "Next, we are going to define a dockerfile, build a docker image from this dockerfile and run this docker image locally.\n",
    "Note: I will assume that we have docker already installed in our environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426450947ae9af1",
   "metadata": {},
   "source": [
    "Defining a Dockerfile\n",
    "\n",
    "Here also I'll copy the code below in order to organize the Jupyter Notebook, but there is also a Dockerfile inside this folder with the same code, in order to call it from the terminal when we'll build the Docker container.\n",
    "\n",
    "Note: The requirements.txt file is in the folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562339e77a43121",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Python base image\n",
    "FROM python:3.10-slim\n",
    "\n",
    "# Setting envs so python don't buffer output\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copying requirements.txt to dir\n",
    "COPY requirements.txt /app/\n",
    "\n",
    "# Dependencies\n",
    "RUN pip install --no-cache-dir --upgrade pip && \\\n",
    "    pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Downloading the Hugging Face model and tokenizer\n",
    "RUN python -c \"from transformers import AutoTokenizer, AutoModelForTokenClassification; \\\n",
    "                AutoTokenizer.from_pretrained('CyberPeace-Institute/SecureBERT-NER'); \\\n",
    "                AutoModelForTokenClassification.from_pretrained('CyberPeace-Institute/SecureBERT-NER');\"\n",
    "\n",
    "# Copying FastAPI app to dir\n",
    "COPY ner_service_fastapi.py /app/\n",
    "\n",
    "# FastApi port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Run\n",
    "CMD [\"uvicorn\", \"ner_service_fastapi:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af439c19111e61",
   "metadata": {},
   "source": [
    "Next, we'll run a shell command to build our docker image using the Dockerfile we created\n",
    "\n",
    "Note: \n",
    "- ner_service_fastapi == tag name\n",
    "- . == search for dockerfile and requirements.txt in current directory"
   ]
  },
  {
   "cell_type": "code",
   "id": "c7ec78ae0f083c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:54:01.013920Z",
     "start_time": "2024-10-16T06:53:56.335787Z"
    }
   },
   "source": [
    "! docker build -t ner_service_fastapi ."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1A\u001B[1B\u001B[0G\u001B[?25l[+] Building 0.0s (0/0)  docker:desktop-linux\r\n",
      "\u001B[?25h\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.0s (0/0)  docker:desktop-linux\r\n",
      "\u001B[?25h\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.0s (0/1)                                    docker:desktop-linux\r\n",
      "\u001B[?25h\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.2s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.2s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.4s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.3s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.5s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.4s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.7s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.6s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 0.8s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.8s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.0s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        0.9s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.1s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        1.1s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.3s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        1.2s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.4s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        1.4s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.6s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        1.5s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.7s (1/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m => [internal] load metadata for docker.io/library/python:3.10-slim        1.6s\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.7s (2/2)                                    docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.10-slim        1.7s\r\n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.8s (11/11)                                  docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.10-slim        1.7s\r\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 2B                                            0.0s\r\n",
      "\u001B[0m\u001B[34m => [1/6] FROM docker.io/library/python:3.10-slim@sha256:1eb5d76bf3e9e612  0.0s\r\n",
      "\u001B[0m\u001B[34m => => resolve docker.io/library/python:3.10-slim@sha256:1eb5d76bf3e9e612  0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 175B                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [2/6] WORKDIR /app                                              0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [3/6] COPY requirements.txt /app/                               0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [4/6] RUN pip install --no-cache-dir --upgrade pip &&     pip   0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [5/6] RUN python -c \"from transformers import AutoTokenizer, A  0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [6/6] COPY ner_service_fastapi.py /app/                         0.0s\r\n",
      "\u001B[0m\u001B[34m => exporting to image                                                     0.1s\r\n",
      "\u001B[0m\u001B[34m => => exporting layers                                                    0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting manifest sha256:3ba42ad3bfbe18d10abcdefafaed560f276e9b73  0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting config sha256:9f1c1efff62814530f03379845b3209bb52baa5256  0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting attestation manifest sha256:6f4e01d131ab253b213f127a237d  0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting manifest list sha256:00e67f7564ca574647b6f4529258f1cd5b6  0.0s\r\n",
      "\u001B[0m\u001B[34m => => naming to docker.io/library/ner_service_fastapi:latest              0.0s\r\n",
      "\u001B[0m\u001B[34m => => unpacking to docker.io/library/ner_service_fastapi:latest           0.0s\r\n",
      "\u001B[0m\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Building 1.9s (11/11) FINISHED                         docker:desktop-linux\r\n",
      "\u001B[34m => [internal] load build definition from Dockerfile                       0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring dockerfile: 1.07kB                                     0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load metadata for docker.io/library/python:3.10-slim        1.7s\r\n",
      "\u001B[0m\u001B[34m => [internal] load .dockerignore                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 2B                                            0.0s\r\n",
      "\u001B[0m\u001B[34m => [1/6] FROM docker.io/library/python:3.10-slim@sha256:1eb5d76bf3e9e612  0.0s\r\n",
      "\u001B[0m\u001B[34m => => resolve docker.io/library/python:3.10-slim@sha256:1eb5d76bf3e9e612  0.0s\r\n",
      "\u001B[0m\u001B[34m => [internal] load build context                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => => transferring context: 175B                                          0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [2/6] WORKDIR /app                                              0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [3/6] COPY requirements.txt /app/                               0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [4/6] RUN pip install --no-cache-dir --upgrade pip &&     pip   0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [5/6] RUN python -c \"from transformers import AutoTokenizer, A  0.0s\r\n",
      "\u001B[0m\u001B[34m => CACHED [6/6] COPY ner_service_fastapi.py /app/                         0.0s\r\n",
      "\u001B[0m\u001B[34m => exporting to image                                                     0.1s\r\n",
      "\u001B[0m\u001B[34m => => exporting layers                                                    0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting manifest sha256:3ba42ad3bfbe18d10abcdefafaed560f276e9b73  0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting config sha256:9f1c1efff62814530f03379845b3209bb52baa5256  0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting attestation manifest sha256:6f4e01d131ab253b213f127a237d  0.0s\r\n",
      "\u001B[0m\u001B[34m => => exporting manifest list sha256:00e67f7564ca574647b6f4529258f1cd5b6  0.0s\r\n",
      "\u001B[0m\u001B[34m => => naming to docker.io/library/ner_service_fastapi:latest              0.0s\r\n",
      "\u001B[0m\u001B[34m => => unpacking to docker.io/library/ner_service_fastapi:latest           0.0s\r\n",
      "\u001B[0m\u001B[?25h\r\n",
      "View build details: \u001B]8;;docker-desktop://dashboard/build/desktop-linux/desktop-linux/ohiynoyohzcto8yormksvmq2a\u001B\\docker-desktop://dashboard/build/desktop-linux/desktop-linux/ohiynoyohzcto8yormksvmq2a\u001B]8;;\u001B\\\r\n",
      "\u001B[1m\r\n",
      "What's next:\u001B[0m\r\n",
      "    View a summary of image vulnerabilities and recommendations → \u001B[36mdocker scout quickview \u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "5f89295f262f8958",
   "metadata": {},
   "source": [
    "Optionally, we can save the docker image to a file"
   ]
  },
  {
   "cell_type": "code",
   "id": "42c2ece602752e14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:54:25.955276Z",
     "start_time": "2024-10-16T06:54:17.434947Z"
    }
   },
   "source": [
    "! docker save -o ner_service_image.tar ner_service_fastapi"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "271181d5558af4cb",
   "metadata": {},
   "source": [
    "After we built our docker image, all that we have to do is to run it! We can turn off internet access also to make sure that the container runs totally on-prem, and it still should work.\n",
    "\n",
    "Note:\n",
    "- -d == run in background mode so we can run shell code after\n",
    "- -p 8000:8000 == publishes and maps 8000 host port to 8000 container port"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2bfd3df8fe68f10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:55:09.787227Z",
     "start_time": "2024-10-16T06:55:08.877282Z"
    }
   },
   "source": [
    "! docker run -d -p 8000:8000 ner_service_fastapi"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683bb0dfa5800d3b965138cae486ec75492886b543dd88c011d2e8adfad56ae9\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "9c43d7779d2c81d4",
   "metadata": {},
   "source": [
    "As earlier, we can go to http://localhost:8000/docs to verify if it's running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194e660e94f1918",
   "metadata": {},
   "source": [
    "Lastly, we'll make a call with an example sentence to verify that we receive a correct response. We can turn off internet here also."
   ]
  },
  {
   "cell_type": "code",
   "id": "95da38070ce85535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:55:16.927624Z",
     "start_time": "2024-10-16T06:55:15.848883Z"
    }
   },
   "source": [
    "!curl -X POST http://localhost:8000/ner -H \"Content-Type: application/json\" -d '{\"text\": \"Kaspersky believes both Shamoon and StoneDrill groups are aligned in their interests.\"}'"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"entities\":[{\"entity_group\":\"SECTEAM\",\"score\":0.9064265489578247,\"word\":\" Kaspersky\",\"start\":0,\"end\":9},{\"entity_group\":\"MAL\",\"score\":0.8394777178764343,\"word\":\" Shamoon\",\"start\":24,\"end\":31},{\"entity_group\":\"APT\",\"score\":0.9263834357261658,\"word\":\" StoneDrill groups\",\"start\":36,\"end\":53}]}"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "aefbdfbc4c9bcccb",
   "metadata": {},
   "source": [
    "We received a response with some entities, all is good!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d053c9a009deb8",
   "metadata": {},
   "source": [
    "Optional: we can stop and remove all running docker containers - but we'll not run this now because we want to use our container as part of our streamlit app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7eef058f353c615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T09:43:35.679243Z",
     "start_time": "2024-10-15T09:43:34.937668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a02efea61620\r\n"
     ]
    }
   ],
   "source": [
    "!docker rm -f $(docker ps -q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
